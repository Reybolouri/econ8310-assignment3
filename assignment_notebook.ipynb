{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e649671-64ae-4692-a381-33974ffa666a",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Econ 8310 - Business Forecasting\n",
    "\n",
    "For homework assignment 3, you will work with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), a more fancier data set.\n",
    "\n",
    "- You must create a custom data loader as described in the first week of neural network lectures [2 points]\n",
    "    - You will NOT receive credit for this if you use the pytorch prebuilt loader for Fashion MNIST!\n",
    "- You must create a working and trained neural network using only pytorch [2 points]\n",
    "- You must store your weights and create an import script so that I can evaluate your model without training it [2 points]\n",
    "\n",
    "Highest accuracy score gets some extra credit!\n",
    "\n",
    "Submit your forked repository URL on Canvas! :) I'll be manually grading this assignment.\n",
    "\n",
    "Some checks you can make on your own:\n",
    "- Did you manually process the data or use a prebuilt loader (see above)?\n",
    "- Does your script train a neural network on the assigned data?\n",
    "- Did your script save your model?\n",
    "- Do you have separate code to import your model for use after training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa30322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gzip, struct\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# read the gzipped IDX file and return it as a NumPy array.\n",
    "def decode_idx(filepath):\n",
    "  \n",
    "    raw = open(filepath, 'rb').read()\n",
    "    data = gzip.decompress(raw)\n",
    "    _, _, dims = struct.unpack_from('>HBB', data, 0)\n",
    "    offset = 4\n",
    "    shape = []\n",
    "    # read each dimension size ,4 bytes per dim\n",
    "    for _ in range(dims):\n",
    "        dim_size, = struct.unpack_from('>I', data, offset)\n",
    "        shape.append(dim_size)\n",
    "        offset += 4\n",
    "    arr = np.frombuffer(data, dtype=np.uint8, offset=offset)\n",
    "    return arr.reshape(shape)\n",
    "\n",
    "#Custom Dataset rthat reads raw IDX gzip files.\n",
    "# decode images and labels, then normalize images to [0.0, 1.0]\n",
    " # Convert to torch.Tensor\n",
    " \n",
    "class IDXFashionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs_path, lbls_path):\n",
    "        images = decode_idx(imgs_path).astype(np.float32) / 255.0\n",
    "        labels = decode_idx(lbls_path).astype(np.int64)\n",
    "        self.X = torch.from_numpy(images).unsqueeze(1)  #  (N,1,28,28)\n",
    "        self.Y = torch.from_numpy(labels)   #(N, )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    " # will return one (image, label) pair\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], int(self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d4781",
   "metadata": {},
   "outputs": [],
   "source": [
    " ##CNN model.   simple CNN with tw-convoloutional blocks \n",
    "# First conv block: 1→16 channels, 5×5 kernel, pad to keep spatial size 28×28 → pool to 14×14\n",
    "# Second conv block: 16→32 channels, again 5×5 → pool to 7×7\n",
    "class CNNModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "#apply conve blocks first then classifier\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    " #here data will load, then train the CNN for 10 epochs, evaluate on the test set each epoch,\n",
    " #and then saves the best performing model weights\n",
    "def execute_training():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_imgs = 'data/train-images-idx3-ubyte.gz'\n",
    "    train_lbls = 'data/train-labels-idx1-ubyte.gz'\n",
    "    test_imgs  = 'data/t10k-images-idx3-ubyte.gz'\n",
    "    test_lbls  = 'data/t10k-labels-idx1-ubyte.gz'\n",
    "#craet PyTorch Datasets and DataLoader\n",
    "    train_ds = IDXFashionDataset(train_imgs, train_lbls)\n",
    "    test_ds  = IDXFashionDataset(test_imgs,  test_lbls)\n",
    "    train_ld = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    test_ld  = DataLoader(test_ds,  batch_size=256, shuffle=False)\n",
    "\n",
    "    # Sanity check one batch\n",
    "    sample_X, sample_y = next(iter(train_ld))\n",
    "    print(f\"[Sanity] X batch shape: {sample_X.shape}, y batch sample: {sample_y[:5].tolist()}\")\n",
    "\n",
    "    model = CNNModel().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    #main trainingloop\n",
    "    for epoch in range(1, 11):\n",
    "        model.train()\n",
    "        for X, y in train_ld:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(X), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # After each epoch evaluate on test set \n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_ld:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                preds = model(X).argmax(dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch:2d}: Test Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'cnn_best_weights.pth')\n",
    "\n",
    "    print(f\"Best Test Accuracy Achieved: {best_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    execute_training()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################\n",
    "# eval_script.py\n",
    "\n",
    "import matplotlib.pyplot as plt                      \n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from train_script import CNNModel, IDXFashionDataset\n",
    "\n",
    "def execute_inference():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # recreate test DataLoader\n",
    "    test_ds = IDXFashionDataset(\n",
    "        'data/t10k-images-idx3-ubyte.gz',\n",
    "        'data/t10k-labels-idx1-ubyte.gz'\n",
    "    )\n",
    "    test_ld = DataLoader(test_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "    # Load model & saved weights\n",
    "    model = CNNModel().to(device)\n",
    "    model.load_state_dict(torch.load('cnn_best_weights.pth', map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # compute overall test accuracy\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_ld:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    print(f\"Final Test Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_ld:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # show first 5\n",
    "            for i in range(5):\n",
    "                img = X_batch[i].cpu().squeeze()      # convert to (28,28) \n",
    "                true_lbl = y_batch[i].item()\n",
    "                pred_lbl = preds[i].item()\n",
    "                plt.imshow(img, cmap='gray')\n",
    "                plt.title(f\"True: {true_lbl}, Pred: {pred_lbl}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            break   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    execute_inference()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
